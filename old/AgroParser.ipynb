{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUyOU4yaItEm"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Parser całej ustawy w PDF → strukturalny JSON\n",
        "Wersja do użycia bezpośrednio w jednej komórce Colab / notebooka.\n",
        "Po wczytaniu funkcji wywołaj np.:\n",
        "\n",
        "    process_act(\"/content/raw.pdf\", \"/content/ustawa_processed.json\")\n",
        "\n",
        "wtedy w `/content/` znajdziesz gotowy plik JSON.\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import pdfplumber  # lightweight PDF text extractor\n",
        "except ImportError as e:\n",
        "    raise ImportError(\"Zainstaluj pdfplumber: pip install pdfplumber\") from e\n",
        "\n",
        "###########################\n",
        "#  META‑DANE (do edycji)  #\n",
        "###########################\n",
        "META = {\n",
        "    \"document_title\": (\n",
        "        \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 5 lutego 2025 r. \"\n",
        "        \"w sprawie ogłoszenia jednolitego tekstu ustawy o ubezpieczeniu społecznym rolników\"\n",
        "    ),\n",
        "    \"date\": \"2025-02-14\",  # data ogłoszenia\n",
        "    \"item\": \"197\",        # pozycja w Dz.U.\n",
        "}\n",
        "\n",
        "###########################\n",
        "#  REGEX + SKRÓTY         #\n",
        "###########################\n",
        "ABBREVIATIONS = {\n",
        "    r\"\\bDz\\. U\\.\": \"Dziennik Ustaw\",\n",
        "    r\"\\b(późn\\.|z późn\\.) zm\\.\": \"z późniejszymi zmianami\",\n",
        "    r\"\\bust\\.\": \"ustęp\",\n",
        "    r\"\\bart\\.\": \"artykuł\",\n",
        "}\n",
        "\n",
        "CHAPTER_RE = re.compile(r\"^Rozdział\\s+(?P<num>[0-9A-Za-z]+)\\s*(?P<title>.*)\")\n",
        "ARTICLE_RE = re.compile(r\"Art\\.\\s*(?P<num>[0-9A-Za-z]+)\\.\")\n",
        "SUBSECTION_RE = re.compile(r\"^(?P<num>[0-9]+[a-z]?)\\)\\s+|^(?P<num_dot>[0-9]+[a-z]?\\.)\\s+\", re.MULTILINE)\n",
        "\n",
        "###########################\n",
        "#  FUNKCJE POMOCNICZE     #\n",
        "###########################\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Usuwa nadmiar białych znaków i rozwija skróty.\"\"\"\n",
        "    text = re.sub(r\"\\s+\", \" \", text.strip())\n",
        "    for abbr, full in ABBREVIATIONS.items():\n",
        "        text = re.sub(abbr, full, text, flags=re.IGNORECASE)\n",
        "    return text\n",
        "\n",
        "\n",
        "def load_pdf_text(pdf_path: Path) -> str:\n",
        "    \"\"\"Łączy tekst ze wszystkich stron PDF‑a w jeden łańcuch.\"\"\"\n",
        "    with pdfplumber.open(str(pdf_path)) as pdf:\n",
        "        pages = [p.extract_text() or \"\" for p in pdf.pages]\n",
        "    return \"\\n\".join(pages)\n",
        "\n",
        "\n",
        "def split_chapters(lines):\n",
        "    \"\"\"Generator zwracający (chapter_header_match, chapter_lines).\"\"\"\n",
        "    current_header = None\n",
        "    buffer = []\n",
        "    for line in lines:\n",
        "        ch_match = CHAPTER_RE.match(line)\n",
        "        if ch_match:\n",
        "            if current_header is not None:\n",
        "                yield current_header, buffer\n",
        "            current_header = ch_match\n",
        "            buffer = []\n",
        "        else:\n",
        "            buffer.append(line)\n",
        "    if current_header is not None:\n",
        "        yield current_header, buffer\n",
        "\n",
        "\n",
        "def parse_subsections(article_body: str):\n",
        "    \"\"\"Zwraca listę podpunktów dla jednego artykułu.\"\"\"\n",
        "    subsections = []\n",
        "    body = re.sub(r\"\\n-\\s+\", \"\\n\", article_body)\n",
        "    matches = list(SUBSECTION_RE.finditer(body))\n",
        "    if not matches:\n",
        "        content = clean_text(body)\n",
        "        if content:\n",
        "            subsections.append({\"number\": \"1\", \"content\": content})\n",
        "        return subsections\n",
        "\n",
        "    for idx, m in enumerate(matches):\n",
        "        start = m.end()\n",
        "        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(body)\n",
        "        num = (m.group(\"num\") or m.group(\"num_dot\") or \"\").replace(\")\", \"\").replace(\".\", \"\").strip()\n",
        "        content = clean_text(body[start:end])\n",
        "        if not content or content.lower().startswith(\"(uchylony)\"):\n",
        "            content = \"Treść uchylona\"\n",
        "        subsections.append({\"number\": num, \"content\": content})\n",
        "    return subsections\n",
        "\n",
        "\n",
        "def parse_articles(chapter_lines):\n",
        "    \"\"\"Zwraca listę artykułów z podpunktami dla danego rozdziału.\"\"\"\n",
        "    joined = \"\\n\".join(chapter_lines)\n",
        "    matches = list(ARTICLE_RE.finditer(joined))\n",
        "    articles = []\n",
        "    for idx, m in enumerate(matches):\n",
        "        art_num = m.group(\"num\")\n",
        "        start = m.end()\n",
        "        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(joined)\n",
        "        body = joined[start:end]\n",
        "        subsections = parse_subsections(body)\n",
        "        articles.append({\"article\": f\"{art_num}.\", \"subsections\": subsections})\n",
        "    return articles\n",
        "\n",
        "###########################\n",
        "#  GŁÓWNA FUNKCJA         #\n",
        "###########################\n",
        "\n",
        "def process_act(pdf_path: str, output_json: str = \"ustawa_processed.json\"):\n",
        "    \"\"\"Konwertuje cały PDF ustawy do strukturalnego JSON‑a.\"\"\"\n",
        "    raw_text = load_pdf_text(Path(pdf_path))\n",
        "    lines = [l for l in raw_text.splitlines() if l.strip()]\n",
        "\n",
        "    chapters_json = []\n",
        "    for header_match, chap_lines in split_chapters(lines):\n",
        "        chap_num = header_match.group(\"num\").rstrip(\".\")\n",
        "        chap_title = header_match.group(\"title\").strip()\n",
        "        articles = parse_articles(chap_lines)\n",
        "        chapters_json.append({\n",
        "            \"number\": chap_num,\n",
        "            \"title\": chap_title,\n",
        "            \"articles\": articles,\n",
        "        })\n",
        "\n",
        "    output = {\n",
        "        \"document\": {\n",
        "            \"title\": META[\"document_title\"],\n",
        "            \"date\": META[\"date\"],\n",
        "            \"item\": META[\"item\"],\n",
        "            \"chapters\": chapters_json,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(output, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"✔️  Zapisano wynik do {output_json}. Rozdziałów: {len(chapters_json)} | Artykułów: {sum(len(c['articles']) for c in chapters_json)}\")"
      ]
    }
  ]
}